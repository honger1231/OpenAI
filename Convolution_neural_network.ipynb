{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC7T_nr41bCy"
      },
      "source": [
        "## ç’°å¢ƒåˆå§‹åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBtXMECz1dOB"
      },
      "outputs": [],
      "source": [
        "# pytorch å¥—ä»¶\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# å…¶ä»–å¥—ä»¶è¼‰å…¥\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 # opencv-python\n",
        "import os\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.datasets import load_iris # è¼‰å…¥é³¶å°¾èŠ±è³‡æ–™é›†\n",
        "from sklearn.model_selection import train_test_split # åˆ‡å‰²è¨“ç·´ã€æ¸¬è©¦è³‡æ–™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSJEmV3RKIx"
      },
      "source": [
        "## 1. Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qab5fSfikxEK"
      },
      "outputs": [],
      "source": [
        "# å‰µå»ºå…©å€‹ç´”é‡\n",
        "scalar_1 = torch.tensor([5.0])\n",
        "scalar_2 = torch.tensor([3.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAD1_97Pk2O4"
      },
      "outputs": [],
      "source": [
        "# åŠ æ³•\n",
        "result = scalar_1 + scalar_2\n",
        "print(f'åŠ æ³•è¨ˆç®—çµæœï¼š{result}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fktTG3DulDJw"
      },
      "outputs": [],
      "source": [
        "# æ¸›æ³•\n",
        "result = scalar_1 - scalar_2\n",
        "print(f'æ¸›æ³•è¨ˆç®—çµæœï¼š{result}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_fgOo-ClCo9"
      },
      "outputs": [],
      "source": [
        "# ä¹˜æ³•\n",
        "result = scalar_1 * scalar_2\n",
        "print(f'ä¹˜æ³•è¨ˆç®—çµæœï¼š{result}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7U5bFv3lPVN"
      },
      "outputs": [],
      "source": [
        "# é™¤æ³•\n",
        "result = scalar_1 / scalar_2\n",
        "print(f'ä¹˜æ³•è¨ˆç®—çµæœï¼š{result}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMDE-xwkXyTu"
      },
      "outputs": [],
      "source": [
        "# å»ºç«‹çŸ©é™£\n",
        "# å€¼å¾ä¸€å€‹å‡å‹»åˆ†å¸ƒæ¡æ¨£ U(âˆ’k,k), k = 1/sqrt(in_features).\n",
        "linear_layer = nn.Linear(1, 1)\n",
        "\n",
        "print(f'éš±è—å±¤çš„æ¬Šé‡ï¼š{linear_layer.weight}')\n",
        "print(f'éš±è—å±¤çš„åå·®å€¼ï¼š{linear_layer.bias}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CSI3sXNrf76"
      },
      "outputs": [],
      "source": [
        "# è¼¸å…¥å€¼ç‚º 5\n",
        "data = torch.tensor([5], dtype=torch.float32)\n",
        "data = linear_layer(data)\n",
        "print(f'è¼¸å‡ºå€¼ï¼š{data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlx3c4SVYJXS"
      },
      "outputs": [],
      "source": [
        "# å¯ä»¥æ§åˆ¶åƒæ•¸\n",
        "linear_layer = nn.Linear(1, 1)\n",
        "linear_layer.weight = nn.Parameter(torch.tensor([[1.0]]))\n",
        "linear_layer.bias = nn.Parameter(torch.tensor([[1.0]]))\n",
        "print(f'éš±è—å±¤çš„æ¬Šé‡ï¼š{linear_layer.weight}')\n",
        "print(f'éš±è—å±¤çš„åå·®å€¼ï¼š{linear_layer.bias}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBC6Lzxxrrkf"
      },
      "outputs": [],
      "source": [
        "# è¼¸å…¥å€¼ç‚º 5\n",
        "data = torch.tensor([[5]], dtype=torch.float32)\n",
        "data = linear_layer(data)\n",
        "print(f'è¼¸å‡ºå€¼ï¼š{data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r_Y1-J7uEMt"
      },
      "source": [
        "## 2. Pytorch vs Numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy æ¬Šé‡\n",
        "weight = np.random.randn(2, 3)\n",
        "bias = np.zeros(shape=(1, 3))\n",
        "print(f'Numpy çŸ©é™£ weight å¤§å°ï¼š{weight.shape}')\n",
        "print(f'Numpy çŸ©é™£ bias å¤§å°ï¼š{bias.shape}')"
      ],
      "metadata": {
        "id": "fnhpZv7TWs7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkywCLbv68qp"
      },
      "source": [
        "Applies a linear transformation to the incoming data: ğ‘¦ = ğ‘¥ğ´^ğ‘‡ + ğ‘ -> [Pyotch Linear function](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z02or_g35TT"
      },
      "outputs": [],
      "source": [
        "# torch æ¬Šé‡\n",
        "linear_layer = nn.Linear(2, 3)\n",
        "print(f'Pytorch çŸ©é™£ weight å¤§å°ï¼š{linear_layer.weight.T.shape}')\n",
        "print(f'Pytorch çŸ©é™£ bias å¤§å°ï¼š{linear_layer.bias.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "521a3BjKWCSq"
      },
      "outputs": [],
      "source": [
        "# è‡ªå‹•æ±‚å°\n",
        "x = torch.tensor(3.0, requires_grad=True) # è¨­ç½®éœ€è¦æ¢¯åº¦\n",
        "y = x**2\n",
        "\n",
        "# è¨ˆç®—æ¢¯åº¦\n",
        "y.backward() # è‡ªå‹•æ±‚å°\n",
        "print(f\"x çš„å€¼ç‚º {x}ï¼Œæ¢¯åº¦ç‚º {x.grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRWmasxuYeci"
      },
      "outputs": [],
      "source": [
        "# æŸ¥çœ‹æœ‰ç„¡GPUï¼Œç„¡å‰‡æŒ‡å®šCPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ç¾åœ¨æœ‰çš„è¨ˆç®—è£ç½®ç‚ºï¼š{device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptz-83Rk7BaC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2.1 Numpy åšçŸ©é™£è¨ˆç®—\n",
        "\n",
        "# ç”¨ numpy ç”¢ç”Ÿéš¨æ©Ÿè³‡æ–™\n",
        "numpy_data = np.random.randn(10, 4) # (10 , 4) (è³‡æ–™æ•¸é‡, ç‰¹å¾µ)\n",
        "\n",
        "# å»ºç«‹åƒæ•¸\n",
        "w1 = np.random.randn(4, 3)          # (4  , 3) (ç‰¹å¾µ   , ç¨®é¡)\n",
        "b1 = np.zeros(shape=(1, 3))\n",
        "\n",
        "# çŸ©é™£ä¹˜æ³•\n",
        "numpy_data = np.dot(numpy_data, w1) + b1 # (10, 4) dot (4, 3)\n",
        "print(f'è¼¸å‡ºç¶­åº¦ï¼š{numpy_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv-lyPYE8nQk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2.2 Pytorch åšçŸ©é™£è¨ˆç®—\n",
        "\n",
        "# ç”¨ torch ç”¢ç”Ÿéš¨æ©Ÿè³‡æ–™\n",
        "tensor_data = torch.randn(10, 4)   # (10 , 4) (è³‡æ–™æ•¸é‡, ç‰¹å¾µ)\n",
        "\n",
        "# å»ºç«‹åƒæ•¸\n",
        "linear_layer = nn.Linear(4, 3)     # (4  , 3) (ç‰¹å¾µ   , ç¨®é¡)\n",
        "\n",
        "# çŸ©é™£ä¹˜æ³•\n",
        "tensor_data = linear_layer(tensor_data) # (10, 4) dot (4, 3)\n",
        "print(f'è¼¸å‡ºç¶­åº¦ï¼š{tensor_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A79mJDXU1Psz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2.3 æ¿€æ´»å‡½æ•¸\n",
        "tensor_data = torch.randn(5, 1)  # 10 ç­†è³‡æ–™, 4 å€‹ç‰¹å¾µ\n",
        "print(f'è¼¸å‡ºå‰ï¼š{tensor_data}')\n",
        "\n",
        "activate_layer = nn.Sigmoid() # ReLU, Sigmoid, Tanh\n",
        "\n",
        "tensor_data = activate_layer(tensor_data)\n",
        "print(f'è¼¸å‡ºå¾Œï¼š{tensor_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjW1hxRI9xgo"
      },
      "source": [
        "## 3. å»ºç«‹åˆ†é¡å™¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISgjn_x1YwBX"
      },
      "outputs": [],
      "source": [
        "# ç¥ç¶“ç¶²è·¯ç‰©ä»¶åŒ–\n",
        "# 1. __init__: æ¨¡å‹æ¶æ§‹\n",
        "# 2. forward: çŸ©é™£ä¹˜æ³•\n",
        "class TestNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TestNet, self).__init__()\n",
        "\n",
        "        self.hidden_layer = nn.Linear(4, 3)\n",
        "\n",
        "    def forward(self, x):         # Input: (10,4)\n",
        "\n",
        "        x = self.hidden_layer(x)  # Layer: (4, 3)\n",
        "\n",
        "        return x                  # Output:(10, 3)\n",
        "\n",
        "test_model = TestNet()\n",
        "\n",
        "tensor_data = torch.randn(10, 4)  # 10 ç­†è³‡æ–™, 4 å€‹ç‰¹å¾µ\n",
        "tensor_data = test_model(tensor_data)\n",
        "print(tensor_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoyNLPfMHQXb"
      },
      "source": [
        "## 4. é³¶å°¾èŠ±åˆ†é¡ (Pytorchç‰ˆæœ¬)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 è³‡æ–™è¼‰å…¥ä»¥åŠè³‡æ–™è½‰æ›"
      ],
      "metadata": {
        "id": "M14dDhyIhLNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zML0AuMHVd_"
      },
      "outputs": [],
      "source": [
        "# è³‡æ–™å‰è™•ç†\n",
        "iris = load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oKj9LI-AMua"
      },
      "outputs": [],
      "source": [
        "# æ¨¡å‹åˆ‡åˆ† 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# è³‡æ–™è½‰æ›ï¼šnumpy -> torch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_KpL_FBC8it"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ Pytorch Dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# ä½¿ç”¨ DataLoaderï¼Œå…·å‚™è¿­ä»£å™¨(Iterator)æ€§è³ª\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 æ­å»ºç¶²è·¯ã€æå¤±å‡½æ•¸èˆ‡å„ªåŒ–å™¨"
      ],
      "metadata": {
        "id": "jiKadQ6PhRBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I36M4O_0HbMI"
      },
      "outputs": [],
      "source": [
        "# å»ºç«‹ç¶²è·¯\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(4, 3)\n",
        "\n",
        "    def forward(self, x):         # A = (è³‡æ–™æ•¸é‡, 4)\n",
        "        x = self.hidden_layer(x)  # B = (4      , 3)\n",
        "        return x                  # A dot B = (è³‡æ–™æ•¸é‡, 3) = C\n",
        "\n",
        "# å‰µå»ºæ¨¡å‹å¯¦ä¾‹\n",
        "model = IrisNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7cTJKvQjVDu"
      },
      "outputs": [],
      "source": [
        "# è¨­ç½®å„ªåŒ–å™¨å’Œæå¤±å‡½æ•¸\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJpYe4H7hbvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 å»ºç«‹è©•ä¼°æ–¹å¼èˆ‡è¨“ç·´"
      ],
      "metadata": {
        "id": "Mgzlgdylhd7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šç¾©è©•ä¼°æ–¹æ³•\n",
        "def eval_model(model, test_loader):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for X_batch, y_batch in test_loader:\n",
        "\n",
        "          outputs = model(X_batch)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "          total += y_batch.size(0)\n",
        "          correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "      print(f'Test Accuracy: {100 * correct / total:.2f}')"
      ],
      "metadata": {
        "id": "lBSv6ajMgdsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNfyKLJULz3C"
      },
      "outputs": [],
      "source": [
        "# è©•ä¼°æ¨¡å‹: Before\n",
        "eval_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdCHn0jVkWXh"
      },
      "outputs": [],
      "source": [
        "# ç›£æ§è¨“ç·´éç¨‹\n",
        "train_losses = []\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "    train_loss = running_train_loss / len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTmDyWiblUy4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 4.4  è¦–è¦ºåŒ–è¨“ç·´éç¨‹\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è©•ä¼°æ¨¡å‹: After\n",
        "eval_model(model, test_loader)"
      ],
      "metadata": {
        "id": "qAxC8teXp88t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmVIWIk2q87c"
      },
      "outputs": [],
      "source": [
        "# ä¿å­˜æ¨¡å‹\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbGNrmQpieNB"
      },
      "source": [
        "## 5. æ‰‹å¯«æ•¸å­—è¾¨è­˜ è³‡æ–™é›†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83lKyrHBi3sq"
      },
      "outputs": [],
      "source": [
        "# åŠ è¼‰MNISTæ•¸æ“šé›†\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG5Y34CzXqrd"
      },
      "outputs": [],
      "source": [
        "print(f'è¨“ç·´è³‡æ–™é›†æ•¸é‡ï¼š{len(train_dataset)}')\n",
        "print(f'æ¸¬è©¦è³‡æ–™é›†æ•¸é‡ï¼š{len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM6bMqvfVWo9"
      },
      "outputs": [],
      "source": [
        "# éš¨æ©ŸæŒ‘å‡ºäº”ç­†è³‡æ–™\n",
        "indices = random.sample(range(len(train_dataset)), 5)\n",
        "samples = [train_dataset[i] for i in indices]\n",
        "\n",
        "# é¡¯ç¤ºåœ–ç‰‡\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i, (image, label) in enumerate(samples):\n",
        "    axes[i].imshow(image.squeeze(), cmap='gray')\n",
        "    axes[i].set_title(f'Label: {label}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFBsqR-3XdoI"
      },
      "source": [
        "## 6. åœ–ç‰‡è³‡æ–™çš„å‰è™•ç†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwVYanM8byvU"
      },
      "outputs": [],
      "source": [
        "# è³‡æ–™å‰è™•ç†\n",
        "transform = transforms.ToTensor() # numpy -> torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khG1UQAVb39O"
      },
      "outputs": [],
      "source": [
        "# å»ºç«‹ numpy è³‡æ–™\n",
        "data = np.array([[10,9,7,4,1]])\n",
        "\n",
        "# è½‰æ›è³‡æ–™é¡åˆ¥ï¼šnumpy -> torch\n",
        "transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp59rBhGeBfI"
      },
      "outputs": [],
      "source": [
        "# ç¬¬ 3 ç­†è³‡æ–™\n",
        "image, label = test_dataset[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUV109hHeneb"
      },
      "outputs": [],
      "source": [
        "# æŸ¥çœ‹è³‡æ–™\n",
        "print(f'å½±åƒå¤§å°ï¼š{image.shape}')\n",
        "print(f'æ¨™ç±¤ï¼š{label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iV8WJzHe0xr"
      },
      "outputs": [],
      "source": [
        "# å½±åƒå‘ˆç¾\n",
        "plt.imshow(image[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOgg0Q-yfBwc"
      },
      "outputs": [],
      "source": [
        "# å½±åƒå‘ˆç¾\n",
        "plt.imshow(image[0], cmap='inferno')\n",
        "# viridis è—è‰²åˆ°ç¶ è‰²\n",
        "# plasma  ç´«è‰²åˆ°é»ƒè‰²\n",
        "# inferno  é»‘è‰²åˆ°é»ƒè‰²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CAdQ5x0f_RZ"
      },
      "outputs": [],
      "source": [
        "# åœ–ç‰‡æ—‹è½‰\n",
        "image, label = test_dataset[500]\n",
        "\n",
        "transform = transforms.RandomRotation(degrees=90)\n",
        "transform_image = transform(image)\n",
        "\n",
        "plt.imshow(transform_image[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acheEA_MhZuU"
      },
      "outputs": [],
      "source": [
        "# åœ–ç‰‡ç¸®æ”¾\n",
        "transform = transforms.Resize((28,42))\n",
        "transform_image = transform(image)\n",
        "\n",
        "plt.imshow(transform_image[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQsWAbcceBxL"
      },
      "outputs": [],
      "source": [
        "# åœ–ç‰‡å‰ªè£\n",
        "transform = transforms.CenterCrop((14,14))\n",
        "transform_image = transform(image)\n",
        "\n",
        "plt.imshow(transform_image[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84JtYVmAiEKK"
      },
      "outputs": [],
      "source": [
        "# æ°´å¹³ç¿»è½‰\n",
        "transform = transforms.RandomHorizontalFlip(p=1)\n",
        "transform_image = transform(image)\n",
        "\n",
        "plt.imshow(transform_image[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¤šç¨®å‰è™•ç†\n",
        "transform = transforms.Compose([      # åŒ…è£å¤šå±¤é‚è¼¯\n",
        "\n",
        "    transforms.CenterCrop((14,14)),   # è£æ¸›\n",
        "    transforms.RandomHorizontalFlip(p=1)   # æ°´å¹³ç¿»è½‰\n",
        "\n",
        "    ])\n",
        "\n",
        "transform_image = transform(image)\n",
        "\n",
        "plt.imshow(transform_image[0], cmap='gray')"
      ],
      "metadata": {
        "id": "czGjmeQSXkse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP-hQpSAXjqQ"
      },
      "source": [
        "## éš¨å ‚ç·´ç¿’ A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_p97W8BmFSQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç·´ç¿’ 1ï¼šè¨­è¨ˆåœ–ç‰‡çš„å‰è™•ç†æµç¨‹\n",
        "### æƒ…å¢ƒï¼šå…¬å¸çš„è³‡æ–™ç§‘å­¸å®¶ç¶“éçµ±è¨ˆç™¼ç¾ï¼Œåœ–ç‰‡æ—‹è½‰45%ï¼Œæ¥è‘—ç¸®æ”¾åˆ°åŸæœ¬åœ–ç‰‡å°ºå¯¸çš„2å€ï¼Œ\n",
        "### æ¨¡å‹è¡¨ç¾æœ€ä½³ï¼Œèº«ç‚ºè³‡æ–™å·¥ç¨‹å¸«çš„ä½ ï¼Œè«‹å¯¦ç¾ä»–çš„éœ€æ±‚ï¼Œçµ¦ä»–ä¸€å€‹å»ºç«‹å¥½çš„ transform ç‰©ä»¶\n",
        "### æç¤ºï¼šéœ€è¦æ³¨æ„é †åºï¼Œæ—‹è½‰45 -> æ”¾å¤§2å€ (åŸå§‹å°ºå¯¸ 28x28)\n",
        "### åƒè€ƒï¼šï¼ˆåœ–ç‰‡è³‡æ–™çš„å‰è™•ç†ï¼‰ï¼šï¼ˆåœ–ç‰‡æ—‹è½‰ï¼‰ã€ï¼ˆåœ–ç‰‡ç¸®æ”¾ï¼‰\n",
        "\n",
        "\n",
        "image, label = test_dataset[1000]\n",
        "print(f'åœ–ç‰‡å¤§å°ï¼š{image.shape}')\n",
        "\n",
        "### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    ?,\n",
        "    ?\n",
        "])\n",
        "\n",
        "### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "transform_image = transform(image)\n",
        "plt.imshow(transform_image[0], cmap='gray')\n",
        "\n",
        "### å¯¦ä½œçµæœ\n",
        "# è¦–è¦ºåŒ–çš„æ•¸å­—æœ‰æ—‹è½‰ï¼Œä¸”é¡¯ç¤ºè¼ƒç‚ºæ¨¡ç³Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LztA-vnBqbGF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç·´ç¿’ 2ï¼šæ­å»ºç°¡æ˜“å•†å“åˆ†é¡æ¨¡å‹\n",
        "### æƒ…å¢ƒï¼šè€é—†æƒ³ä½¿ç”¨é¡ç¥ç¶“ç¶²è·¯ä¾†åšå•†å“åˆ†é¡ï¼Œè«‹å¹«ä»–å¯¦ä½œå‡ºä¾†\n",
        "### æ¨¡å‹è¨­è¨ˆç‚ºå…©å±¤ï¼š(100, 256) -> (256, 10)\n",
        "### åƒè€ƒï¼š4.1 æ­å»ºç¶²è·¯ï¼‰\n",
        "\n",
        "class Three_layer_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Three_layer_model, self).__init__()\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        self.layer_1 = ?\n",
        "        self.layer_2 = ?\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        x = ?\n",
        "        x = ?\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Three_layer_model()\n",
        "\n",
        "tensor_data = torch.randn(30, 100)  # 30 ç­†è³‡æ–™, 100 å€‹ç‰¹å¾µ\n",
        "tensor_data = model(tensor_data)    # å‰å‘å‚³æ’­\n",
        "print(tensor_data)\n",
        "### å¯¦ä½œçµæœ\n",
        "# åªè¦ model(tensor_data) èƒ½åšä¸€æ¬¡å‰å‘å‚³æ’­å³å¯"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ç·´ç¿’ 3ï¼šæ­å»ºæ‰‹å¯«æ•¸å­—è¾¨è­˜æ¨¡å‹"
      ],
      "metadata": {
        "id": "FdqDNyjT6FNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDQujm-7R8Hj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 æ­å»ºæ¨¡å‹\n",
        "### æƒ…å¢ƒï¼šåœ°æ–¹çš„éƒµå±€å§”è¨—ä½ åšæ‰‹å¯«æ•¸å­—è¾¨è­˜ï¼Œè«‹æ­å»ºä¸€å€‹ä¸‰å±¤çš„ç¶²è·¯çš„æ¨¡å‹\n",
        "### æ¨¡å‹è¨­è¨ˆç‚º(784, 512) -> (ReLU) -> (512, 10)ï¼Œ\n",
        "### åƒè€ƒï¼šï¼ˆ4.1 æ­å»ºç¶²è·¯ï¼‰ã€ï¼ˆ2.3 æ¿€æ´»å‡½æ•¸ï¼‰\n",
        "\n",
        "class Three_layer_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Three_layer_model, self).__init__()\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        self.flatten = nn.Flatten() # è³‡æ–™æ”¤å¹³ï¼Œ2ç¶­åº¦åœ–ç‰‡ï¼Œè½‰ç‚º1ç¶­è³‡æ–™\n",
        "\n",
        "        self.layer_1 = ?\n",
        "        self.relu = ?\n",
        "        self.layer_2 = ?\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = ?\n",
        "        x = ?\n",
        "        x = ?\n",
        "\n",
        "        ### å¯¦ä½œç·´ç¿’ ###\n",
        "\n",
        "        return x\n",
        "\n",
        "image, label = test_dataset[3]\n",
        "model = Three_layer_model()\n",
        "data = model(image) # æ¸¬è©¦\n",
        "print(data.shape)\n",
        "\n",
        "### å¯¦ä½œç·´ç¿’\n",
        "# æ¨¡å‹å»ºç«‹å®Œæˆï¼Œæ¸¬è©¦çš„çµæœå¯ä»¥é¡¯ç¤ºè³‡æ–™ï¼Œå‰‡æˆåŠŸ\n",
        "# å³å¯é€²è¡Œä¸‹æ–¹çš„æ¨¡å‹è¨“ç·´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlbSjB3vSBQY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.2 è¨“ç·´æ¨¡å‹\n",
        "# ç”¨æ–¼è¨˜éŒ„æå¤±å’Œæº–ç¢ºç‡çš„åˆ—è¡¨\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 5\n",
        "# è¨“ç·´æ¨¡å‹\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # å‰å‘å‚³æ’­\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # åå‘å‚³æ’­å’Œå„ªåŒ–\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvyDCQ8yt7aq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.3 è©•ä¼°æ¨¡å‹\n",
        "model.eval()\n",
        "running_test_loss = 0.0\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss = running_test_loss / len(test_loader)\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrLDIsPPTvkt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.4 è§€çœ‹è¨“ç·´éç¨‹\n",
        "# è¦–è¦ºåŒ–æå¤±å€¼\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# è¦–è¦ºåŒ–æº–ç¢ºç‡\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.5 è§€çœ‹ç…§ç‰‡çµæœ -> [è£½ä½œåœ–ç‰‡](https://docs.google.com/drawings)\n",
        "image_file = 'test.png'\n",
        "\n",
        "if os.path.isfile(image_file):\n",
        "  image = cv2.imread(image_file)\n",
        "  image = cv2.resize(image, (28,28), interpolation=cv2.INTER_AREA)\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  gray_image = gray_image.reshape((1, 1, 28, 28)) # 2ç¶­ æ“´å¢ç‚º 4 ç¶­åº¦\n",
        "  gray_image = gray_image / 255\n",
        "  gray_image = torch.Tensor(gray_image)\n",
        "  plt.imshow(image)\n",
        "\n",
        "else:\n",
        "  print('No file is found')"
      ],
      "metadata": {
        "id": "TFDfyEid4gLG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.6 æ¨¡å‹è©•ä¼°\n",
        "if os.path.isfile(image_file):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(gray_image)\n",
        "      prob, predicted = torch.max(outputs.data, 1)\n",
        "      print(f'é æ¸¬é¡åˆ¥ï¼š{predicted.item()}')"
      ],
      "metadata": {
        "id": "OZmyT-Ni7v6w",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L67FJ6qiHs1Z"
      },
      "source": [
        "## 7.æ‰‹å¯«æ•¸å­—è¾¨è­˜ + CNN + GPU è¨“ç·´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYltRBTRIGOE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 7.1 å®šç¾©è³‡æ–™è™•æ–¹å¼èˆ‡è³‡æ–™é›†\n",
        "\n",
        "# å‰ç½®è¨­å®š\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# åŠ è¼‰ MNIST æ•¸æ“šé›†\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVUlf6VVIIkB"
      },
      "outputs": [],
      "source": [
        "#@title 7.2 å»ºç«‹æ¨¡å‹èˆ‡å„ªåŒ–å™¨\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "image, label = test_dataset[3]\n",
        "\n",
        "print(model(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDeQeY9PvVt7"
      },
      "outputs": [],
      "source": [
        "#@title 7.3 å‰µå»ºæ¨¡å‹èˆ‡è¨“ç·´ç­–ç•¥\n",
        "model = CNN().to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "\n",
        "# è¨­ç½®æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ev_l3mHHtdD"
      },
      "outputs": [],
      "source": [
        "#@title 7.4 è¨“ç·´æ¨¡å‹\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        images = images.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        labels = labels.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqMM2870NpY2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 7.6 æ¸¬è©¦æ¨¡å‹\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        labels = labels.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kM-IT1swX9G"
      },
      "source": [
        "## éš¨å ‚ç·´ç¿’ B"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ç·´ç¿’ å¢åŠ ç¶²è·¯çš„æ·±åº¦"
      ],
      "metadata": {
        "id": "HThoNy43a4-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHUNGnUJwZpa"
      },
      "outputs": [],
      "source": [
        "### æƒ…å¢ƒï¼šå°æ–¼ä»¥ä¸‹çš„å·ç©ç¥ç¶“ç¶²è·¯é€²è¡Œæ”¹è‰¯ï¼Œè«‹å¹«å®ƒç–ŠåŠ æ›´æ·±çš„ä¸€å±¤å·ç© +Maxpooling\n",
        "### æ–°çš„ä¸€å±¤ Conv2d(64, 128)\n",
        "### åƒè€ƒï¼šï¼ˆ7.2 å»ºç«‹æ¨¡å‹èˆ‡å„ªåŒ–å™¨ï¼‰\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # (28,28) -> (14,14)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # (14,14) -> (7,7)\n",
        "\n",
        "         ## å¯¦ä½œç·´ç¿’ ##\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels= ? , out_channels= ? , kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)   # (7,7) -> (3,3)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
        "\n",
        "         ## å¯¦ä½œç·´ç¿’ ##\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        ## å¯¦ä½œç·´ç¿’ ##\n",
        "\n",
        "        # å¯åƒè€ƒä¸Šæ–¹çš„ç¬¬ä¸€å±¤èˆ‡ç¬¬äºŒå±¤\n",
        "        x = ?\n",
        "        x = ?\n",
        "\n",
        "        ## å¯¦ä½œç·´ç¿’ ##\n",
        "\n",
        "        x = x.view(-1, 128 * 3 * 3) ## å¯¦ä½œç·´ç¿’ ##\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "image, label = test_dataset[3]\n",
        "data = model(image) # æ¸¬è©¦\n",
        "print(data.shape)\n",
        "### å¯¦ä½œç·´ç¿’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf3CJCC5wnLw"
      },
      "source": [
        "### è¨“ç·´ & æ¸¬è©¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soA74PScwik6"
      },
      "outputs": [],
      "source": [
        "# å‰µå»ºæ¨¡å‹å¯¦ä¾‹\n",
        "model = CNN().to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "\n",
        "# è¨­ç½®æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# è¨“ç·´æ¨¡å‹\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        images = images.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        labels = labels.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# æ¸¬è©¦æ¨¡å‹\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        labels = labels.to('cuda') # æ”¾å…¥ GPU è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "AC7T_nr41bCy",
        "XZSJEmV3RKIx",
        "6r_Y1-J7uEMt",
        "TjW1hxRI9xgo",
        "YoyNLPfMHQXb",
        "M14dDhyIhLNE",
        "jiKadQ6PhRBn",
        "Mgzlgdylhd7V",
        "nbGNrmQpieNB",
        "rFBsqR-3XdoI",
        "LP-hQpSAXjqQ",
        "FdqDNyjT6FNm",
        "L67FJ6qiHs1Z",
        "-kM-IT1swX9G",
        "HThoNy43a4-y",
        "Vf3CJCC5wnLw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}