{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "60vuqHmhapgf",
        "h3uVCmckKz_A",
        "BXImT6yUrX2m",
        "SO8D4FK_w0Ry",
        "Og16o96v0PN_",
        "kzqiJQAn2Qch",
        "ygdr_BUn3tGC",
        "Ujf2fFVJJ_C9",
        "Ya2SyEv0aj2n",
        "vToCwqdqPMvk",
        "SU4_UI9dWN_L",
        "HqOKfeKzWfyr",
        "4GmvD8KBPwYR",
        "uObHycw9nXMT",
        "qKR_airG8REW",
        "dnuFxZ_9njDe"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 安裝與載入套件\n",
        "執行階段類型，請切換到 T4 or TPU"
      ],
      "metadata": {
        "id": "60vuqHmhapgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安裝套件\n",
        "!pip install datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install textwrap3\n",
        "!pip install pyarrow\n",
        "!pip install opencc\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "yijVu2Fr-oSY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 套件載入\n",
        "\n",
        "# 載入 transformers 套件\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModel, AutoConfig\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 載入其他套件\n",
        "import numpy as np\n",
        "import textwrap # 打印用套件\n",
        "import opencc # 簡轉繁\n",
        "import os\n",
        "\n",
        "# 載入 pytorch 套件\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "oLsRTNiVjcM3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 使用 transformers 模型"
      ],
      "metadata": {
        "id": "h3uVCmckKz_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 情緒分析模型"
      ],
      "metadata": {
        "id": "BXImT6yUrX2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入情緒分析的二元分類模型\n",
        "# DistilBERT - Base, Uncased - Finetuned - SST-2 - Englist\n",
        "# SST-2: Stanford Sentiment Treebank 2\n",
        "\n",
        "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "pipe = pipeline(\"text-classification\", model=model_name, device=0)"
      ],
      "metadata": {
        "id": "A68d3tXFn1-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 輸入一個字串\n",
        "results = pipe(\"This restaurant is awesome\")\n",
        "\n",
        "for result in results:\n",
        "  print(result['label'])\n",
        "  print(result['score'])"
      ],
      "metadata": {
        "id": "nPNhJuRXpWW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 輸入一個串列\n",
        "results = pipe([\"This restaurant is awesome\", \"what are you doing?\"])\n",
        "\n",
        "for result in results:\n",
        "  print(result['label'])\n",
        "  print(result['score'])"
      ],
      "metadata": {
        "id": "ZfcaVsxZpYsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 使用語言翻譯模型"
      ],
      "metadata": {
        "id": "SO8D4FK_w0Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 英文轉中文\n",
        "translator = pipeline(\"translation_en_to_zh\", model=\"Helsinki-NLP/opus-mt-en-zh\", device=0)\n",
        "# 簡中轉繁中\n",
        "converter = opencc.OpenCC('s2t')"
      ],
      "metadata": {
        "id": "PAL6mCxMwmcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 進行翻譯\n",
        "translation = translator(\"This restaurant is awesome\")\n",
        "\n",
        "for result in translation:\n",
        "    print(f'簡體輸出：{result[\"translation_text\"]}')\n",
        "    traditional_chinese = converter.convert(result['translation_text'])\n",
        "    print(f'繁體輸出：{traditional_chinese}')"
      ],
      "metadata": {
        "id": "YyKUBw82xB-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 QA問答"
      ],
      "metadata": {
        "id": "Og16o96v0PN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立模型與資料\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", device=0)\n",
        "\n",
        "context = \"\"\"\n",
        "Hugging Face is a company that focuses on natural language processing technology.\n",
        "They have developed many popular open-source tools and libraries, including the Transformers and Datasets libraries.\n",
        "These tools are widely used for building and deploying machine learning models.\n",
        "\"\"\"\n",
        "question = \"What does Hugging Face focus on?\""
      ],
      "metadata": {
        "id": "oKDAb6-HxkL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 進行 QA 問答\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {result['answer']}\")"
      ],
      "metadata": {
        "id": "jv2sKrje0Tn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQuAD (Stanford Question Answering Dataset)\n",
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset('squad')\n",
        "print(raw_datasets)"
      ],
      "metadata": {
        "id": "LDVhEIH80A-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 命名實體識別 (Named Entity Recognition, NER)"
      ],
      "metadata": {
        "id": "kzqiJQAn2Qch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 建立模型與資料\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", device=0)\n",
        "\n",
        "text = \"Hugging is a company based in New York City. The CEO is Clem Delangue.\""
      ],
      "metadata": {
        "id": "4tuA5uuI1RFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 進行文字的實體識別\n",
        "entities = ner_pipeline(text)\n",
        "\n",
        "for entity in entities:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
      ],
      "metadata": {
        "id": "ESOOA27E2X3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 文字生成 (繁體)"
      ],
      "metadata": {
        "id": "ygdr_BUn3tGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CKIP Lab 中文詞知識庫小組\n",
        "generator = pipeline(\"text-generation\", model=\"ckiplab/gpt2-base-chinese\", truncation=True, device=0)\n"
      ],
      "metadata": {
        "id": "67T3ZMQ33r0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 準備\n",
        "prompt = \"我隔壁有一個鄰居叫小王，\""
      ],
      "metadata": {
        "id": "iG79qJxuv6e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 單筆文字生成\n",
        "text = generator(prompt, max_length=100, num_return_sequences=1, temperature=1)\n",
        "\n",
        "# 返回的文字把空格去掉\n",
        "text = text[0]['generated_text'].replace(' ','')\n",
        "print(f'生成文字：{text}')"
      ],
      "metadata": {
        "id": "WnzxYZQ5v5LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 多筆文字生成\n",
        "texts = generator(prompt, max_length=100, num_return_sequences=3, temperature=1)\n",
        "\n",
        "for i, text in enumerate(texts):\n",
        "  text = text['generated_text'].replace(' ','')\n",
        "  print(f\"{i+1}: {text}\")"
      ],
      "metadata": {
        "id": "4CVV48ad37mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看模型資訊\n",
        "model_name = \"ckiplab/gpt2-base-chinese\"\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "# print(config)\n",
        "\n",
        "max_length = config.max_position_embeddings\n",
        "print(f\"輸入的最大長度: {max_length}\")"
      ],
      "metadata": {
        "id": "YlvFaFDwEk4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看模型參數量\n",
        "model = AutoModel.from_pretrained(model_name, config=config)\n",
        "num_parameters = model.num_parameters()\n",
        "print(f\"模型的參數量: {num_parameters}\")"
      ],
      "metadata": {
        "id": "ajcS9KYVGAE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. BERT 模型微調"
      ],
      "metadata": {
        "id": "Ujf2fFVJJ_C9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 載入數據集"
      ],
      "metadata": {
        "id": "Ya2SyEv0aj2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載數據集\n",
        "dataset = load_dataset('imdb')\n",
        "\n",
        "print(f'資料輪廓：{dataset}')"
      ],
      "metadata": {
        "id": "z3s1hCoUjWbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 觀測資料：取前180個文字符號\n",
        "\n",
        "data_index = 5\n",
        "text_data = dataset['train'][data_index]['text'][:180]\n",
        "text_label = dataset['train'][data_index]['label']\n",
        "text_data = textwrap.fill(f'{text_data}', width=50) # 50個字換行\n",
        "\n",
        "print('[內文]')\n",
        "print(text_data)\n",
        "print('[標籤]')\n",
        "print(text_label)"
      ],
      "metadata": {
        "id": "vD27C8LslwVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用部分資料 ：2000 vs 500\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(2000))\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(500))"
      ],
      "metadata": {
        "id": "f6JJyhrik5ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載tokenizer和模型\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "izSZktVqm3y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立文字資訊\n",
        "input_text = 'Hi I am a human'\n",
        "print(f'文字訊息：{input_text}')"
      ],
      "metadata": {
        "id": "EYE4wTdlm8Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對文字進行編碼\n",
        "encode_text = tokenizer.encode(input_text)\n",
        "print(f'編碼訊息：{encode_text}')"
      ],
      "metadata": {
        "id": "42kqhVtrnREa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對數字進行解碼\n",
        "text = tokenizer.decode(encode_text)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "JPG2nyp7nSCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載tokenizer和模型\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# 數據預處理函數\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "qVxplWjr0gbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 BERT模型建立 & 微調\n",
        "[TrainingArguments 文件](https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/trainer#transformers.TrainingArguments)\n"
      ],
      "metadata": {
        "id": "vToCwqdqPMvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',              # 儲存結果的資料夾\n",
        "    num_train_epochs=3,                  # 總共訓練 3 輪\n",
        "    per_device_train_batch_size=8,       # 每個設備的 batch_Size 為 8\n",
        "    warmup_steps=500,                    # 熱身步數為 500\n",
        "    weight_decay=0.01,                   # 權重衰減係數為 0.01\n",
        "    evaluation_strategy=\"epoch\",         # 每個 epoch 結束後進行評估\n",
        ")"
      ],
      "metadata": {
        "id": "hLBF_UFz0ggS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 資料集與超參數設定\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 模型\n",
        "    args=training_args,                  # 訓練參數\n",
        "    train_dataset=train_dataset,         # 訓練資料集\n",
        "    eval_dataset=test_dataset            # 測試資料集\n",
        ")"
      ],
      "metadata": {
        "id": "bAhoJBZ4VsX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 pipeline 建立模型\n",
        "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0)\n",
        "label_map = {0: 'negative', 1: 'positive'}"
      ],
      "metadata": {
        "id": "WXwFRv9uUAvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 訓練前測試 (Before test)"
      ],
      "metadata": {
        "id": "SU4_UI9dWN_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 抽一筆測試資料\n",
        "data_index = 3\n",
        "\n",
        "sample = test_dataset[data_index]\n",
        "input_text = sample['text']\n",
        "\n",
        "print(f'輸入內容：{input_text[:50]}(前50個字)')\n",
        "print(f\"真實標籤：{label_map[sample['label']]}\")"
      ],
      "metadata": {
        "id": "URXiYbU1O6jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 觀看結果\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"Score：{predict[0]['score']}\")\n",
        "print(f\"預測結果：{predict[0]['label']}\") # LABEL_0：負面, LABEL_1：正面"
      ],
      "metadata": {
        "id": "VzLdIQcTPGvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正面資料測試\n",
        "input_text = 'I love this movie!'\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"預測結果：{predict[0]['label']}\")\n",
        "print(f\"預測結果：{predict[0]['score']}\")"
      ],
      "metadata": {
        "id": "K3Z7SMw4jS1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 負面資料測試\n",
        "input_text = 'What a mess of this movie!'\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"預測結果：{predict[0]['label']}\")\n",
        "print(f\"預測結果：{predict[0]['score']}\")"
      ],
      "metadata": {
        "id": "W8e0WltSUKTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 模型訓練"
      ],
      "metadata": {
        "id": "HqOKfeKzWfyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型訓練\n",
        "trainer.train()\n",
        "\n",
        "# 切為評估模式\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "lVqMhTBo0gqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 微調後測試"
      ],
      "metadata": {
        "id": "4GmvD8KBPwYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 抽一筆測試資料\n",
        "data_index = 3\n",
        "\n",
        "sample = test_dataset[data_index]\n",
        "input_text = sample['text']\n",
        "\n",
        "print(f'輸入內容：{input_text[:50]}(前50個字)')\n",
        "print(f\"真實標籤：{label_map[sample['label']]}\")"
      ],
      "metadata": {
        "id": "Q_t4967JMr8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 觀看結果\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"Score：{predict[0]['score']}\")\n",
        "print(f\"預測結果：{predict[0]['label']}\") # LABEL_1：負面, LABEL_1：正面"
      ],
      "metadata": {
        "id": "HhpoweQBNEfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正面資料測試\n",
        "input_text = 'I love this movie!'\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"Score：{predict[0]['score']}\")\n",
        "print(f\"預測結果：{predict[0]['label']}\") # LABEL_1：負面, LABEL_1：正面"
      ],
      "metadata": {
        "id": "rwZKZtpHMuuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 負面資料測試\n",
        "input_text = 'What a mess of this movie!'\n",
        "predict = nlp(input_text)\n",
        "\n",
        "print(f\"Score：{predict[0]['score']}\")\n",
        "print(f\"預測結果：{predict[0]['label']}\") # LABEL_1：負面, LABEL_1：正面"
      ],
      "metadata": {
        "id": "iUktx2zwjhes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 隨堂練習"
      ],
      "metadata": {
        "id": "uObHycw9nXMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 練習 1：詩歌的文字生成\n",
        "### 情境：喜愛創作的你，想透過 GPT 取得一些創意與靈感\n",
        "### 試著提供開頭的線索，接著讓 GPT 輸出剩下的創作\n",
        "### 參考：（1.5 文字生成 (繁體)）\n",
        "\n",
        "### 實作練習 ###\n",
        "\n",
        "prompt = '?' # 歌詞、唐詩都可\n",
        "generator = ?\n",
        "\n",
        "text = ?\n",
        "\n",
        "### 實作練習 ###\n",
        "\n",
        "text = text[0]['generated_text'].replace(' ','')\n",
        "print(f'生成文本：{text}')\n",
        "\n",
        "### 練習結果\n",
        "# 接著你提供的 prompt，能成功產生出延續的文字"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0xnb8Nu2rDpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 練習 2：文件的資訊檢索\n",
        "### 情境：你的朋友是一個歷史軍事迷，他對於戰爭史非常感到興趣，\n",
        "### 他想請你從二次世界大戰的歷史文本中，幫他尋找三個問題的答案。\n",
        "### 參考章節: 1.3 QA問答\n",
        "# 1. 問題：\n",
        "#   1.1 第二次世界大戰什麼時候開始？\n",
        "#   1.2 主要的戰場在哪裡？\n",
        "#   1.3 誰贏得了這場戰爭？\n",
        "\n",
        "context = \"\"\"\n",
        "World War II (1939-1945) was a global war that involved most of the world's nations,\n",
        "forming two opposing military alliances: the Allies and the Axis.\n",
        "It began on September 1, 1939, when Germany invaded Poland.\n",
        "The war ended in 1945 with the victory of the Allies.\n",
        "Major theaters of the war included Europe, East Asia, and the Pacific.\n",
        "The war caused tens of millions of deaths and widespread destruction.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"When did World War II begin?\",\n",
        "    \"Where are the main battlefields?\",\n",
        "    \"Who won the war?\",\n",
        "]\n",
        "\n",
        "### 實作練習 ###\n",
        "\n",
        "  ? # 建模型\n",
        "  ? # 使用迴圈\n",
        "    ? # QA問答\n",
        "  print(f\"Question: {question}\")\n",
        "  print(f\"Answer: {result['answer']}\\n\")\n",
        "\n",
        "### 實作練習 ###\n",
        "\n",
        "### 實作結果\n",
        "# Question: When did World War II begin?\n",
        "# Answer: September 1, 1939\n",
        "\n",
        "# Question: Where are the main battlefields?\n",
        "# Answer: Europe, East Asia, and the Pacific\n",
        "\n",
        "# Question: who won the war?\n",
        "# Answer: Allies"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EDTKeUr9fpeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 練習 3：Google 評論監控\n",
        "### 情境：隔壁的咖啡廳老闆，想請你做一個評論監控器，可以分析咖啡廳的google評論，\n",
        "### 使得他能在最短時間，得知近期的客人對店有不滿或者抱怨\n",
        "### 參考章節: 1.1 情緒分析模型\n",
        "\n",
        "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "pipe = pipeline(\"text-classification\", model=model_name, device=0)\n",
        "\n",
        "test_messages = [\n",
        "                  \"Awesome, I love the coffee in this shop\",\n",
        "                  \"This cafe is terrible\",\n",
        "                  \"This place has the best cakes in the world\"\n",
        "                ]\n",
        "\n",
        "### 實作練習 ###\n",
        "### 提示：先用 for 跑串列，再用 if-else\n",
        "### 判斷 result 裡的資訊次否為 NEGATIVE\n",
        "?\n",
        "  ?\n",
        "  ?\n",
        "\n",
        "    print('This is an issue from comments!')\n",
        "    print(message)\n",
        "\n",
        "### 實作練習 ###\n",
        "\n",
        "### 實作結\n",
        "# This is an issue from comments!\n",
        "# This cafe is terrible"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N8afK70CnYk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generative Adversarial Network (GAN)"
      ],
      "metadata": {
        "id": "qKR_airG8REW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 資料前處理與設定資料集"
      ],
      "metadata": {
        "id": "dnuFxZ_9njDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定裝置與資料前處理方式\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "-2ssMa7hnT5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建 Dataset 與 Dataloader\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "r6yJLBhGdGUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 建立模型與優化器"
      ],
      "metadata": {
        "id": "NrotMrrjnsaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.2.1 設計模型\n",
        "# 建立生成模型\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "# 建立判別模型\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nq_m6NFqdJpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.2.2 建立模型\n",
        "# 超參數設定\n",
        "z_dim = 100\n",
        "mnist_dim = 784\n",
        "\n",
        "# 建立模型\n",
        "G = Generator(g_input_dim=z_dim, g_output_dim=mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jl0oLy2ydO36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.2.3 建立損失函數與優化器\n",
        "# 損失函數\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 優化值\n",
        "learning_rate = 0.0002\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=learning_rate)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d1UfyDIR8sKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 建構模型的訓練流程"
      ],
      "metadata": {
        "id": "ZjpgEamSs2Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.3.1 判別模型的訓練流程\n",
        "def D_train(x):\n",
        "\n",
        "    D.zero_grad()\n",
        "\n",
        "    # 丟入真實的圖片\n",
        "    real_data_size = x.shape[0]\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(real_data_size, 1)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # 丟入生成的圖片\n",
        "    z = torch.randn(real_data_size, z_dim).to(device)\n",
        "    x_fake, y_fake = G(z), torch.zeros(real_data_size, 1).to(device)\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # 兩種資料做梯度，只更新生成模型的權重\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lIuhwiXL8rpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.3.2 建立生成模型的訓練流程\n",
        "def G_train(x):\n",
        "\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    y = torch.ones(batch_size, 1).to(device)\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oeNQZrtg-pYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.4 訓練模型\n",
        "n_epoch = 20\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "metadata": {
        "id": "7rUI-qQL80vB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.5 生成圖片\n",
        "with torch.no_grad():\n",
        "    test_z = torch.randn(batch_size, z_dim).to(device)\n",
        "    generated = G(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rLZ7bMl7d18u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}